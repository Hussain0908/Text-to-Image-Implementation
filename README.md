# Text-to-Image-Implementation
This app takes in an input of text and generates an image based on the input.

This project leverages the power of the model Stable Diffusion v1-4, a state-of-the-art latent diffusion model imported from Hugging Face. This model excels at generating images based on textual descriptions.

Utilizing Python, we seamlessly integrate Stable Diffusion v1-4 into our framework by importing the necessary dependencies, including the Hugging Face Transformers library. Through this powerful library, we gain direct access to the model's capabilities, unlocking creative possibilities in text-to-image generation. This includes the Hugging Face token imported from the secondary file.

This application requires a graphics card which has at least 4gb of VRAM. The graphics card uses Nvidias CUDA to run the image processing. 

Other dependencies include pytorch, PILLOW, & tkinter.




